{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Assistant\n",
    "\n",
    "Additional concepts:\n",
    "\n",
    "- Thread management for multiple users\n",
    "  - Using shelves to store the user threads\n",
    "  - Thread will be created or reused as different users access the assistant\n",
    "- Relationships in files\n",
    "\n",
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import shelve\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from openai.types import FileObject\n",
    "from openai.types.beta import Thread\n",
    "from openai.types.beta.threads import Run\n",
    "from openai.types.beta.threads.message_content_image_file import MessageContentImageFile\n",
    "from openai.types.beta.threads.message_content_text import MessageContentText\n",
    "from openai.types.beta.threads.messages import MessageFile\n",
    "from PIL import Image\n",
    "\n",
    "# List of assistants created\n",
    "ai_assistants = []\n",
    "# List of threads created\n",
    "ai_threads = []\n",
    "# List of files uploaded\n",
    "ai_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "email_URI = os.getenv(\"EMAIL_URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_thread(thread):\n",
    "    for item in ai_threads:\n",
    "        if item.id == thread.id:\n",
    "            return\n",
    "    ai_threads.append(thread)\n",
    "    print(\"Added thread: \", thread.id, len(ai_threads))\n",
    "\n",
    "def check_if_thread_exists(user_id):\n",
    "    with shelve.open(\"threads_db\") as threads_shelf:\n",
    "        return threads_shelf.get(user_id, None)\n",
    "\n",
    "def store_thread(user_id, thread):\n",
    "    with shelve.open(\"threads_db\", writeback=True) as threads_shelf:\n",
    "        add_thread(thread)\n",
    "        threads_shelf[user_id] = thread.id\n",
    "\n",
    "def clear_shelves():\n",
    "    with shelve.open(\"assistant_db\") as assistant_shelf:\n",
    "        assistant_shelf.clear()\n",
    "    with shelve.open(\"threads_db\") as threads_shelf:\n",
    "        threads_shelf.clear()\n",
    "\n",
    "clear_shelves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AzureOpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the latest stock price by ticker symbol using Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol: str) -> float:\n",
    "    stock = yf.Ticker(symbol)\n",
    "    return stock.history(period=\"1d\")[\"Close\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send an email using Logic Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_logic_apps_email(to: str, content: str) -> None:\n",
    "    try:\n",
    "        json_payload = {\"to\": to, \"content\": html.unescape(content)}\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        response = requests.post(email_URI, json=json_payload, headers=headers)\n",
    "        if response.status_code == 202:\n",
    "            print(\"Email sent to: \" + json_payload[\"to\"])\n",
    "    except:\n",
    "        print(\"Failed to send email via Logic Apps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Assistant tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [\n",
    "    {\"type\": \"code_interpreter\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "\n",
    "def upload_file(client: AzureOpenAI, path: str) -> FileObject:\n",
    "    print(path)\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        return client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "arr = os.listdir(DATA_FOLDER)\n",
    "assistant_files = []\n",
    "for file in arr:\n",
    "    filePath = DATA_FOLDER + file\n",
    "    assistant_file = upload_file(client, filePath)\n",
    "    ai_files.append(assistant_file)\n",
    "    assistant_files.append(assistant_file)\n",
    "\n",
    "file_ids = [file.id for file in assistant_files]\n",
    "file_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Assistant and a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Sales Assistant\",\n",
    "    instructions=\"You are a sales assistant. You can answer questions related to customer orders.\",\n",
    "    tools=tools_list,\n",
    "    model=api_deployment_name,\n",
    "    file_ids=file_ids,\n",
    ")\n",
    "ai_assistants.append(assistant)\n",
    "##thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_assistant_file(file_id:str):\n",
    "    response_content = client.files.content(file_id)\n",
    "    return response_content.read()\n",
    "\n",
    "def print_messages(name: str, messages: Iterable[MessageFile]) -> None:\n",
    "    message_list = []\n",
    "\n",
    "    # Get all the messages till the last user message\n",
    "    for message in messages:\n",
    "        message_list.append(message)\n",
    "        if message.role == \"user\":\n",
    "            break\n",
    "\n",
    "    # Reverse the messages to show the last user message first\n",
    "    message_list.reverse()\n",
    "\n",
    "    # Print the user or Assistant messages or images\n",
    "    for message in message_list:\n",
    "        for item in message.content:\n",
    "            # Determine the content type\n",
    "            if isinstance(item, MessageContentText):\n",
    "                if message.role == \"user\":\n",
    "                    print(f\"user: {name}:\\n{item.text.value}\\n\")\n",
    "                else:\n",
    "                    print(f\"{message.role}:\\n{item.text.value}\\n\")\n",
    "                file_annotations = item.text.annotations\n",
    "                if file_annotations:\n",
    "                    for annotation in file_annotations:\n",
    "                        file_id = annotation.file_path.file_id\n",
    "                        content = read_assistant_file(file_id)\n",
    "                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n",
    "            elif isinstance(item, MessageContentImageFile):\n",
    "                # Retrieve image from file id                \n",
    "                data_in_bytes = read_assistant_file(item.image_file.file_id)\n",
    "                # Convert bytes to image\n",
    "                readable_buffer = io.BytesIO(data_in_bytes)\n",
    "                image = Image.open(readable_buffer)\n",
    "                # Resize image to fit in terminal\n",
    "                width, height = image.size\n",
    "                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n",
    "                # Display image\n",
    "                image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(name, user_id, prompt: str) -> None:\n",
    "\n",
    "    thread_id = check_if_thread_exists(user_id)\n",
    "\n",
    "     # If a thread doesn't exist, create one and store it\n",
    "    if thread_id is None:\n",
    "        print(f\"Creating new thread for {name} with user_id {user_id}\")\n",
    "        thread = client.beta.threads.create()\n",
    "        store_thread(user_id, thread)\n",
    "        thread_id = thread.id\n",
    "    # Otherwise, retrieve the existing thread\n",
    "    else:\n",
    "        print(f\"Retrieving existing thread for {name} with user_id {user_id}\")\n",
    "        thread = client.beta.threads.retrieve(thread_id)\n",
    "        add_thread(thread)\n",
    "\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. Do not provide explanations for the answers.\"\n",
    "        + \"The current date and time is: \"\n",
    "        + datetime.now().strftime(\"%x %X\")\n",
    "        + \". \",\n",
    "    )\n",
    "\n",
    "    print(\"processing ...\")\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run.status == \"completed\":\n",
    "            # Handle completed\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            print_messages(name, messages)\n",
    "            break\n",
    "        if run.status == \"failed\":\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            print_messages(name, messages)\n",
    "            # Handle failed\n",
    "            break\n",
    "        if run.status == \"expired\":\n",
    "            # Handle expired\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"cancelled\":\n",
    "            # Handle cancelled\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"requires_action\":            \n",
    "            pass\n",
    "        else:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a conversation with the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"John\", \"user_123\", \"What customers are in Florida?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Mary\", \"user_234\", \"What seller has had the most sales?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"John\", \"user_123\", \"What is the most sold product?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Mary\", \"user_234\", \"Chart product sales by State.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(client):\n",
    "    print(\"Deleting: \", len(ai_assistants), \" assistants.\")\n",
    "    for assistant in ai_assistants:\n",
    "        print(client.beta.assistants.delete(assistant.id))\n",
    "    print(\"Deleting: \", len(ai_threads), \" threads.\")\n",
    "    for thread in ai_threads:\n",
    "        print(client.beta.threads.delete(thread.id))\n",
    "    print(\"Deleting: \", len(ai_files), \" files.\")\n",
    "    for file in ai_files:\n",
    "        print(client.files.delete(file.id))\n",
    "        \n",
    "cleanup(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
