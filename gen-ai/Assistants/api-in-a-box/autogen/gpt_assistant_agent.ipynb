{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Backed by Azure OpenAI Assistant API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a OpenAI Assistant in Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen import UserProxyAgent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\", \n",
    "    max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "assistant_id = os.environ.get(\"ASSISTANT_ID\", None)\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "    {\n",
    "        \"model\": os.environ.get(\"OPENAI_GPT_DEPLOYMENT\", None),\n",
    "        \"api_key\": os.environ.get(\"OPENAI_KEY\", None),\n",
    "        \"base_url\": os.environ.get(\"OPENAI_URI\", None),\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": os.environ.get(\"OPENAI_VERSION\", None),\n",
    "    }\n",
    "],\n",
    "}\n",
    "assistant_config = {\n",
    "    # define the openai assistant behavior as you need\n",
    "}\n",
    "oai_agent = GPTAssistantAgent(\n",
    "    name=\"oai_agent\",\n",
    "    instructions=\"I'm an openai assistant running in autogen\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a test question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to oai_agent):\n",
      "\n",
      "Tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33moai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Tell me a joke.', 'role': 'assistant'}, {'content': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\", 'role': 'user'}], summary=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\", cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(recipient=oai_agent,\n",
    "    message=\"Tell me a joke.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Use OpenAI Assistant Built-in Tools and Function Calling\n",
    "\n",
    "##### Code Interpreter\n",
    "\n",
    "The Code Interpreter empowers your agents to write and execute Python code in a secure environment provide by OpenAI. This unlocks several capabilities, including but not limited to:\n",
    "\n",
    "- Process data: Handle various data formats and manipulate data on the fly.\n",
    "- Generate outputs: Create new data files or even visualizations like graphs.\n",
    "- ...\n",
    "\n",
    "Using the Code Interpreter with the following configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(code_oai_agent) - model: gpt-4\n",
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:instructions not match, skip assistant(asst_7jHEroxGAuEnL1vjUFQUNaVE): You are a code assistant tool that can run code in the code interpreter\n",
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"code_interpreter\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "code_oai_agent = GPTAssistantAgent(\n",
    "    name=\"code_oai_agent\",\n",
    "    instructions=\"You are a code assistant tool that can run Python code\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to code_oai_agent):\n",
      "\n",
      "Run a Monty Hall problem simulation 10000 times, and              tell me how often you win by switching doors.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcode_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "After simulating the Monty Hall problem 10,000 times and always switching doors, the contestant won approximately 66.44% of the time.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Run a Monty Hall problem simulation 10000 times, and              tell me how often you win by switching doors.', 'role': 'assistant'}, {'content': 'After simulating the Monty Hall problem 10,000 times and always switching doors, the contestant won approximately 66.44% of the time.\\n', 'role': 'user'}], summary='After simulating the Monty Hall problem 10,000 times and always switching doors, the contestant won approximately 66.44% of the time.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(recipient=code_oai_agent,\n",
    "    message=\"Run a Monty Hall problem simulation 10000 times, and tell me how often you win by switching doors.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To get the file.id, you can employ two methods:\n",
    "\n",
    "Azure OpenAI Playground: Leverage the Azure OpenAI Playground, an interactive platform accessible at https://oai.azure.com, to upload your files and obtain the corresponding file IDs.\n",
    "\n",
    "Code-Based Uploading: Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    base_url=os.environ.get(\"BASE_URL\"),\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    api_version=os.environ.get(\"OPENAI_VERSION\")\n",
    ")\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"mydata.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### File Search\n",
    "\n",
    "The File Search tool empowers your agents to tap into knowledge beyond its pre-trained model. This allows you to incorporate your own documents and data, such as product information or code files, into your agent's capabilities.\n",
    "\n",
    "Using the File Search with the following configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI client config of GPTAssistantAgent(files_oai_agent) - model: gpt-4-1106-preview\n",
      "No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's how to obtain the vector_store.id using two methods:\n",
    "\n",
    "OpenAI Playground: Leverage the OpenAI Playground, an interactive platform accessible at https://platform.openai.com/playground, to create a vector store, upload your files, and add it into your vector store. Once complete, you'll be able to retrieve the associated vector_store.id.\n",
    "\n",
    "Code-Based Uploading:Alternatively, you can upload files and retrieve their file IDs programmatically using the following code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store created: vs_djfk94WgbkQNpXrfvy0xDBlF\n",
      "File batch status: completed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FileCounts' object has no attribute 'processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 4: Verify Completion (Optional)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile batch status:\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_batch\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploaded file count:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfile_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed\u001b[49m)\n",
      "File \u001b[0;32m~/ai-in-a-box/.venv/lib/python3.11/site-packages/pydantic/main.py:811\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FileCounts' object has no attribute 'processed'"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    base_url=os.environ.get(\"BASE_URL\"),\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    api_version=os.environ.get(\"OPENAI_VERSION\")\n",
    ")\n",
    "\n",
    "# Step 1: Create a Vector Store\n",
    "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
    "print(\"Vector Store created:\", vector_store.id)  # This is your vector_store.id\n",
    "\n",
    "# Step 2: Prepare Files for Upload\n",
    "file_paths = [\"./Gotcha-Covered-Design-Style-Guide.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Step 3: Upload Files and Add to Vector Store (with status polling)\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# Step 4: Verify Completion (Optional)\n",
    "print(\"File batch status:\", file_batch.status)\n",
    "print(\"Uploaded file count:\", file_batch.file_counts.completed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI client config of GPTAssistantAgent(files_oai_agent) - model: gpt-4-1106-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No matching assistant found, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        {\"type\": \"retrieval\"}\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "files_oai_agent = GPTAssistantAgent(\n",
    "    name=\"files_oai_agent\",\n",
    "    instructions=\"You are a files search assistant tool\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Clearing thread thread_36qXzpJmgJhAcA20CmPEHSTL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to files_oai_agent):\n",
      "\n",
      "What's a modern urban style like?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mfiles_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "Modern urban design style is characterized by simplicity, sleekness, and a minimalist approach. It showcases true form and function, featuring cleaner lines and open floor plans. Originating from old factories and industrial spaces, modern urban design employs stripped-back architecture and elements like salvaged or repurposed items. It is inspired by fuss-free approaches using basic materials such as untreated timber beams, brick, reinforced concrete, and exposed metal structures. The design style incorporates raw materials and builds around the structure of the existing space, often with strong horizontal and vertical lines and a simple, neutral color palette accented by a bold color. Metallic hardware like stainless steel or nickel is common, with a \"less is more\" approach to accessories and decorations. Modern urban design favors large windows that let in plenty of natural light and streamline furniture without frills or added decorations【0:8†Gotcha-Covered-Design-Style-Guide.pdf】.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's a modern urban style like?\", 'role': 'assistant'}, {'content': 'Modern urban design style is characterized by simplicity, sleekness, and a minimalist approach. It showcases true form and function, featuring cleaner lines and open floor plans. Originating from old factories and industrial spaces, modern urban design employs stripped-back architecture and elements like salvaged or repurposed items. It is inspired by fuss-free approaches using basic materials such as untreated timber beams, brick, reinforced concrete, and exposed metal structures. The design style incorporates raw materials and builds around the structure of the existing space, often with strong horizontal and vertical lines and a simple, neutral color palette accented by a bold color. Metallic hardware like stainless steel or nickel is common, with a \"less is more\" approach to accessories and decorations. Modern urban design favors large windows that let in plenty of natural light and streamline furniture without frills or added decorations【0:8†Gotcha-Covered-Design-Style-Guide.pdf】.\\n', 'role': 'user'}], summary='Modern urban design style is characterized by simplicity, sleekness, and a minimalist approach. It showcases true form and function, featuring cleaner lines and open floor plans. Originating from old factories and industrial spaces, modern urban design employs stripped-back architecture and elements like salvaged or repurposed items. It is inspired by fuss-free approaches using basic materials such as untreated timber beams, brick, reinforced concrete, and exposed metal structures. The design style incorporates raw materials and builds around the structure of the existing space, often with strong horizontal and vertical lines and a simple, neutral color palette accented by a bold color. Metallic hardware like stainless steel or nickel is common, with a \"less is more\" approach to accessories and decorations. Modern urban design favors large windows that let in plenty of natural light and streamline furniture without frills or added decorations【0:8†Gotcha-Covered-Design-Style-Guide.pdf】.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(recipient=files_oai_agent,\n",
    "    message=\"What's a modern urban style like?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Function Calling empowers you to extend the capabilities of your agents with your pre-defined functionalities, which allows you to describe custom functions to the Assistant, enabling intelligent function selection and argument generation.\n",
    "\n",
    "Using the Function calling with the following configuration.\n",
    "\n",
    "# learn more from https://platform.openai.com/docs/guides/function-calling/function-calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:OpenAI client config of GPTAssistantAgent(functions_oai_agent) - model: gpt-4-1106-preview\n",
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:tools not match, skip assistant(asst_4IKDwvrd2ZUPh8pdIejuitCt): tools set(), functions set()\n",
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:Matching assistant found, using the first matching assistant: {'id': 'asst_5hVWKd6jO25al9cMeLUjZ24x', 'created_at': 1715891542, 'description': None, 'instructions': 'You are a weather assistant', 'metadata': {}, 'model': 'gpt-4-1106-preview', 'name': 'functions_oai_agent', 'object': 'assistant', 'tools': [FunctionTool(function=FunctionDefinition(name='get_current_weather', description='Returns the current weather data for a specified location.', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'location'}}, 'required': ['location']}), type='function')], 'tool_resources': ToolResources(code_interpreter=None, file_search=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to functions_oai_agent):\n",
      "\n",
      "What's the weather like in Redmond, WA?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_current_weather...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(get_current_weather, Success: True) : {'location': 'Redmond, WA', 'temperature': 22.5, 'description': 'Partly cloudy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mfunctions_oai_agent\u001b[0m (to user_proxy):\n",
      "\n",
      "The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's the weather like in Redmond, WA?\", 'role': 'assistant'}, {'content': 'The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\\n', 'role': 'user'}], summary='The current weather in Redmond, WA is partly cloudy with a temperature of 22.5°C.\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.function_utils import get_function_schema\n",
    "\n",
    "@user_proxy.register_for_execution()\n",
    "def get_current_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the current weather for a specified location.\n",
    "\n",
    "    Args:\n",
    "    location (str): The location to get the weather for.\n",
    "\n",
    "    Returns:\n",
    "    Union[str, dict]: A dictionary with weather details..\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulated response\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 22.5,\n",
    "        \"description\": \"Partly cloudy\"\n",
    "    }\n",
    "\n",
    "api_schema = get_function_schema(\n",
    "    get_current_weather,\n",
    "    name=get_current_weather.__name__,\n",
    "    description=\"Returns the current weather data for a specified location.\"\n",
    ")\n",
    "\n",
    "assistant_config = {\n",
    "    \"tools\": [\n",
    "        api_schema\n",
    "    ],\n",
    "}\n",
    "\n",
    "functions_oai_agent = GPTAssistantAgent(\n",
    "    name=\"functions_oai_agent\",\n",
    "    instructions=\"You are a weather assistant\",\n",
    "    llm_config=llm_config,\n",
    "    assistant_config=assistant_config,\n",
    "    function_map={\n",
    "        \"get_current_weather\": get_current_weather\n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(recipient=functions_oai_agent,\n",
    "    message=\"What's the weather like in Redmond, WA?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
